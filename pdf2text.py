# -*- coding: utf-8 -*-
"""Pdf2Text

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14shUevOrF8eEkvIh6KPIUOL3no0xrlhW
"""

# Install dependencies
!pip install pdfplumber pytesseract pdf2image Pillow tqdm transformers sentencepiece
!apt install poppler-utils tesseract-ocr -y

# Imports
import pdfplumber
import pytesseract
from pdf2image import convert_from_path
from tqdm import tqdm
from PIL import Image
from transformers import pipeline
import os

# Summarizer
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

#  Core Extraction Function
def extract_text_from_pdf(pdf_path, output_txt_path=None):
    all_text = ""
    page_num = 0

    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in tqdm(pdf.pages, desc="Extracting Text"):
                text = page.extract_text()
                page_num += 1
                if text and text.strip():
                    all_text += f"\n--- Page {page_num} (Text Extracted) ---\n{text}\n"
                else:
                    img = page.to_image(resolution=300).original
                    ocr_text = pytesseract.image_to_string(img)
                    all_text += f"\n--- Page {page_num} (OCR Extracted) ---\n{ocr_text}\n"
    except Exception as e:
        print(f"[ERROR] Direct extraction failed, switching to OCR only. Reason: {e}")
        pages = convert_from_path(pdf_path)
        for i, img in enumerate(tqdm(pages, desc="Running OCR")):
            ocr_text = pytesseract.image_to_string(img)
            all_text += f"\n--- Page {i + 1} (OCR Only) ---\n{ocr_text}\n"

    # Save if requested
    if output_txt_path:
        with open(output_txt_path, "w", encoding="utf-8") as f:
            f.write(all_text)
        print(f"\n Text saved to {output_txt_path}")

    return all_text


#  Text Summarization
def summarize_text(text, max_length=500, min_length=100):
    print("\n Generating summary")
    try:
        chunks = []
        text = text.replace("\n", " ")
        chunk_size = 2000
        for i in range(0, len(text), chunk_size):
            chunk = text[i:i+chunk_size]
            summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)
            chunks.append(summary[0]['summary_text'])
        final_summary = "\n".join(chunks)
        print("\n Summary generated successfully.")
        return final_summary
    except Exception as e:
        print(f"[ERROR] Summarization failed: {e}")
        return "[Error in summarization]"


#  OCR Improvements
def preprocess_image_for_ocr(img):
    # Convert image to grayscale and binarize for better OCR accuracy
    gray = img.convert("L")  # grayscale
    bw = gray.point(lambda x: 0 if x < 200 else 255, '1')
    return bw


#  Full Pipeline Execution
from google.colab import files

print(" Upload a PDF file to begin")
uploaded = files.upload()
pdf_file = list(uploaded.keys())[0]
print(f"\n Uploaded: {pdf_file}")

output_name = pdf_file.replace(".pdf", "_output.txt")

# Extract Text
extracted_text = extract_text_from_pdf(pdf_file, output_name)

# Summarize the text
summary = summarize_text(extracted_text)

# Save summary
summary_path = pdf_file.replace(".pdf", "_summary.txt")
with open(summary_path, "w", encoding="utf-8") as f:
    f.write(summary)

# Download both
print("\n Downloading results...")
files.download(output_name)
files.download(summary_path)

print("\n Process complete!")